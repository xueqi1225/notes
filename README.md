# notes

你有没有在大数据平台上设计和实施过数据分析解决方案？如果有，请分享你的经验和成果。

```
在大数据平台上，我设计并实施过数据分析解决方案。经验包括使用Hadoop、Spark、Flink等技术进行数据处理和分析，实现了用户行为分析、日志分析等功能。成果包括大幅提高数据处理速度、降低资源消耗和为业务部门提供关键洞察。
```

在处理大规模数据时，如何进行性能调优以提高处理速度和效率？

```
处理大规模数据时，优化方法包括数据分区、缓存、广播变量、序列化等。还需要关注并行度、任务资源分配、存储格式等，以提高处理速度和效率。
```

你使用过哪些数据同步工具？请分享你的经验和使用场景。

```
我使用过数据同步工具如Sqoop、DataX、Kettle等。在数据迁移、实时同步等场景中都有实际应用。
```

你如何处理海量数据的存储和管理？请分享你的经验和使用的工具。

```
处理海量数据存储和管理时，我使用过HDFS、HBase、Cassandra等分布式存储系统。这些工具能够提高数据的可扩展性和可靠性。
```

请描述你在大数据任务调度方面的经验和使用的工具。

```
我在大数据任务调度方面的经验包括使用Airflow、Azkaban和Oozie等工具进行任务的定时和依赖管理。
```

你有没有使用过Kafka流式处理框架？如果有，请分享你的经验和使用场景。

```
我使用过Kafka流式处理框架，应用场景包括实时日志处理、实时用户行为分析等。
```

你如何处理数据质量问题？请分享你的经验和解决方案。

```
处理数据质量问题时，我会制定数据质量规则、使用数据清洗工具（如Trifacta、OpenRefine）以及构建数据质量监控系统。
```

你如何设计和优化大数据架构，以提高系统的可扩展性和可靠性？

```
设计和优化大数据架构时，我会关注系统可扩展性、可靠性、容错性等，通过使用微服务、数据分片、负载均衡等技术来提高系统性能。
```

你如何保证数据同步的准确性和一致性？在同步过程中如何处理数据冲突和数据丢失问题？

```
保证数据同步准确性和一致性的方法包括使用事务、幂等操作、冲突解决策略等。在同步过程中，可以使用双写、日志补偿等方法处理数据冲突和数据丢失问题。
```

你使用过哪些大数据存储引擎？在选择存储引擎时，你会考虑哪些因素？

```
我使用过HBase、Cassandra、Hive等大数据存储引擎。在选择存储引擎时，我会考虑性能、可扩展性、数据模型和查询需求等因素。
```

你如何处理大规模数据的备份和恢复？在备份和恢复过程中如何保证数据的完整性和一致性？

```
处理大规模数据备份和恢复时，我会使用分布式备份工具（如HBase Snapshots、DistCp）以及增量备份策略。在备份和恢复过程中，可以使用一致性哈希、Merkle树等技术保证数据完整性和一致性。
```

你如何对大数据系统进行监控和性能优化？在监控和性能优化方面，你会关注哪些指标和问题？

```
对大数据系统进行监控和性能优化时，我会关注系统资源利用率、任务执行时间、吞吐量、延迟等指标。在优化方面，我会关注数据倾斜、内存管理、网络传输等问题。
```

你在处理海量数据时，如何进行数据清洗和去重？在数据清洗和去重方面，你使用过哪些工具和技术？

```
在处理海量数据时，我会使用数据清洗框架（如Spark、Flink）进行数据清洗和去重。在数据清洗和去重方面，我使用过Bloom过滤器、Distinct、Deduplication等技术。
```

## 腾讯面试




（1）各种场景模拟，1 亿数据，20 亿用户，大表处理
```
大数据场景处理：在处理1亿数据、20亿用户、大表等场景时，可以采用分布式计算框架（如Hadoop、Spark、Flink）来处理大量数据。你可以使用分区、分桶等技术来优化数据存储和查询性能。

```

（2）如何确定某个 java 程序将 CPU 跑满之后导致该原因的线程？
```
Java 程序 CPU 占用问题：可以使用线程分析工具（如VisualVM、JConsole、jstack）来定位 CPU 占用高的线程。通过分析线程堆栈，可以找出导致 CPU 跑满的原因。

```

（3）Phoenix 和 HBase 是如何关联的？一个 SQL 是怎么同步写入到 HBase 的？
```
Phoenix 和 HBase 关联：Phoenix 是一个基于 HBase 的 SQL 引擎，它将 SQL 查询转换为 HBase API 调用，实现对 HBase 表的查询和更新。当执行一个 SQL 语句时，Phoenix 会将其解析、优化并生成对应的 HBase API 调用来操作 HBase 表。

```

（4）一年的窗口怎么每 5 分钟输出一次结果。（RK 状态+CK 时间点+定时器）
```
一年窗口每5分钟输出结果：可以使用 Flink 或 Spark Streaming 的窗口操作，设置窗口长度为一年，滑动间隔为5分钟。同时，使用定时器或水位线来触发窗口计算。

```

（5）flink 和 spark Streaming 对比？
```
Flink 和 Spark Streaming 对比：

Flink 更适合实时流处理，具有低延迟和高吞吐量；Spark Streaming 是基于微批处理的，延迟相对较高。
Flink 支持事件时间和处理时间，具有精确一次处理语义；Spark Streaming 仅支持处理时间，并且精确一次处理语义需要额外配置。
Flink 支持 Savepoint 和 Stateful Computation；Spark Streaming 需要依赖外部存储进行状态管理。


```

（6）flink 的时间语义，精准一次性这些
```
Flink 时间语义和精确一次性：Flink 支持事件时间和处理时间语义，可以处理乱序数据。精确一次处理语义是通过端到端的 Exactly-Once 保证来实现的，包括状态一致性和数据源/数据接收器的一致性。

```

（7）HBase 的二级索引？大表的处理？
```
HBase 二级索引和大表处理：HBase 二级索引可通过协处理器实现，如 HBase-Indexer，以提高查询性能。大表处理可通过预分区、合并小文件、数据压缩等方式优化。

```

（8）spark SQL 和 hive on spark 有什么区别？
```
Spark SQL 和 Hive on Spark 区别：
Spark SQL 是基于 Spark 引擎的 SQL 查询工具，可以直接处理多种数据格式。
Hive on Spark 是将 Spark 作为 Hive 的执行引擎，使用 Spark 替代默认的 MapReduce 引擎。

```

（9）flink 的精准一次？幂等和事务使用有什么问题？ck 连续超时有什么影响？
```
Flink 精确一次、幂等和事务使用问题：Flink 精确一次通过 Checkpoint 机制实现，它可能会影响性能。幂等操作可以确保在失败后重试时不会影响结果。事务用于保证输出操作的原子性。连续 Checkpoint 超时可能导致数据丢失或系统无法恢复。

```

（10）hbase 如果问怎么快速检索 1 亿数据？布隆过滤器已经开辟了最大长度，不能在开辟了怎么处理？
```
HBase 快速检索亿级数据：可以使用协处理器进行二级索引优化，或者使用 HBase 的 Scan 接口结合 Filter 进行范围查询。如果布隆过滤器已达到最大长度，可以考虑使用多级布隆过滤器或其他数据结构。

```

（11）spark 场景题和对应的优化处理？
```
Spark 场景题和优化处理：针对具体场景，可以通过调整 Spark 配置、使用缓存、广播变量、分区数、持久化等方式进行优化。

```

（12）flink 事务 sink 写文件，是怎么处理的？对应的文件存在哪里？详细说下
```
Flink 事务 Sink 写文件：Flink 的事务 Sink 通过 TwoPhaseCommitSinkFunction 实现，它将数据写入预提交的临时文件，然后在事务提交时将临时文件重命名为最终文件。这些文件通常存储在分布式文件系统（如 HDFS）中。

```

（13）一个 flink 任务一直在重启？怎么判断原因？
```
Flink任务重启原因判断：首先查看 Flink 任务的异常日志，找出导致任务重启的异常原因。常见原因包括内存溢出、数据倾斜、程序逻辑错误等。针对不同原因，可以调整配置、优化程序、调整数据分区等方法解决。

```

（14）CBO 和 RBO 的区别？说说常见的 RBO 的规则？
```
CBO 和 RBO 区别：

CBO（成本优化器）：基于统计信息和查询成本模型选择最优的执行计划，适用于复杂查询和大数据量场景。
RBO（规则优化器）：根据预定义的一组规则选择执行计划，不需要统计信息，适用于简单查询和小数据量场景。
常见的 RBO 规则包括谓词下推、列裁剪、连接顺序调整等。

```

（15）flink 的反压你们是怎么处理的？怎么判定的？
```
Flink 反压处理：Flink 通过背压机制自动调整数据流速率，以保持系统稳定。你可以通过监控系统的吞吐量、延迟等指标来判断是否存在反压问题。针对反压问题，可以调整并行度、增加资源、优化程序等方法解决。

```

（16）flink SQL 的整个底层执行过程
```
Flink SQL 底层执行过程：

解析：将 SQL 语句解析成抽象语法树（AST）。

验证：检查 SQL 语句的语法和语义是否正确。

优化：根据规则和成本模型进行优化，生成最优的逻辑计划。

生成物理计划：将逻辑计划转换为物理计划，包括选择具体的算子实现和数据交换策略。

生成 Flink 任务：将物理计划转换为 Flink 的 DataStream 或 DataSet API。

执行 Flink 任务：提交任务到 Flink 集群进行执行。

```


